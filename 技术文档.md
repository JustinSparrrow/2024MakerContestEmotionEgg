# 技术路线
## agents
采用调用星火大模型api的方法，将识别到的情绪和语音糅合起来发送给api，api返回响应后，再使用GPT-SoVITS训练出的人声模型根据不同的情绪特征输出出来。

## 情绪小人
根据情绪的不同使用opencv展示不同的小人动画。

## 视频面部情绪识别
采用开源的DeepFace库进行情绪识别，将识别到的情绪存入本地后传给agents。

## 语音情绪识别
使用pyaudio实现语音的输入和输出，使用开源库whisper进行语音转文字的功能，再通过SpeechEmotionRecognition-Pytorch开源库进行情绪识别，将识别到的情绪和用户的语音输入传给agents的api，再返回相应的功能。

## 开源库使用
[yeyupiaoling / SpeechEmotionRecognition-Pytorch: 基于Pytorch实现的语音情感识别](https://github.com/yeyupiaoling/SpeechEmotionRecognition-Pytorch)
[RVC-Boss / GPT-SoVITS : 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)](https://github.com/RVC-Boss/GPT-SoVITS)
[serengil/deepface: A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python](https://github.com/serengil/deepface)
[openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision](https://github.com/openai/whisper)